---
title: "Best Practices"
slug: "/best_practice"
---

import useBaseUrl from '@docusaurus/useBaseUrl';

# Best Practices

## Introduction

All scientists generate scientific data independently of whether they are working practically or theoretically, and produce data such as protocols, analytical data, or data from calculations. These data can be [domain-specific](/docs/domain_guide) and should always be accompanied by [metadata](/docs/metadata) that fully describe the data.

On this page, we provide best practices for data publication in field-specific as well as generic research data repositories, while best practices for Chemotion Repository are provided on a separate page about [Chemotion Repository](/docs/chemotion_repo). Additionally, we include best practices on special aspects, such as how to use PIDs of datasets in academic publishing.

:::danger Notice:
Field-specific repositories should be the first choice as these repositories enhance the FAIRness of data on behalf of the submitters. To retain the same level of FAIRness, data publication in generic repositories requires manual FAIRification.
:::

## How to use dataset PIDs in publications

During deposition of research data, a [persistent identifier](/docs/pid) is assigned to the data. Authors should use PIDs in their article for interlinking in two main ways:

- For corresponding data, i.e. directly underlying the results reported in the article, add the PID to the article's [Data Availability Statement](/docs/data_availability_statement). If you believe that your data publication is as important as the article itself, add your dataset to the references as well.
- For datasets published by other researchers and reused within a study, add the PID to the reference section of the manuscript and cite within the text accordingly.

:::info Notice:
This distinction is important, because the link to the dataset in the DOI metadata of scientific articles is differently set, depending on whether the dataset is a directly related source of information or a referenced source of other researchers and its information is reused.
:::

In addition, the PID of a related dataset could also be additionally mentioned in the supplementary PDF, if such a document is generated.

## Best practices for field-specific repositories

Using a field-specific repository such as [Chemotion ELN](/docs/chemotion_eln) in combination with its repository [Chemotion Repository](/docs/chemotion_repo) realises efficient data handling for synthetically working chemists. The entire Chemotion package allows researchers to collect, analyse, process, store, and publish various types of analytical data attached to reactions and samples in one digital environment.

For field-specific repositories such as Chemotion ELN with Chemotion Repository, the data is collected along the scientific workflows, analytical data files are automatically converted to open formats, controlled vocabularies or ontologies are used to describe data, and analysis data is interconnected to reactions and samples, hence, chemical structures. 

During the seamless export from the ELN into the repository, [persistent identifiers (DOIs)](/docs/pid) are assigned to the deposited data. Chemotion Repository [provides](https://www.chemotion.net/docs/repo/doi) DOIs for reactions, samples and analysis data. Moreover, Collection DOIs can be assigned for a set of reactions, samples, and analyses to assemble a study. This study can then directly correspond to a published scientific article and be referenced in a bundled manner within the data availability statement.

Additionally, Chemotion Repository is connected to other databases (e.g. [PubChem](https://pubchem.ncbi.nlm.nih.gov/)) and repositories (e.g. [NMRShiftDB2](https://nmrshiftdb.nmr.uni-koeln.de/), soon to be superseded by [nmrXiv](https://nmrxiv.org/)), to ensure best visibility and a user-friendly search of original research data.

### Best practice examples for field-specific repositories

 Several working groups of NFDI4Chem and beyond already deposit research data in the [Chemotion-Repository](https://www.chemotion-repository.net/welcome). For a better understanding of how data publications are linked to related journal publications, the following examples including their data (open-access) can be viewed:

- [Modular Synthesis of New Pyrroloquinoline Quinone Derivatives](/docs/tba)
- [Modular Synthesis of trans‐A2B2‐Porphyrins with Terminal Esters: Systematically Extending the Scope of Linear Linkers for Porphyrin‐Based MOFs](https://doi.org/10.1002/chem.202003885)
- [Next Generation of Zinc Bisguanidine Polymerization Catalysts towards Highly Crystalline, Biodegradable Polyesters](https://doi.org/10.1002/anie.202008473)
- [Synthesis of new pyrazolo[1,2,3]triazines by cyclative cleavage of pyrazolyltriazenes](https://doi.org/10.3762/bjoc.17.187)
- [Exceptional Substrate Diversity in Oxygenation Reactions Catalyzed by a Bis(μ-oxo) Copper Complex](http://dx.doi.org/10.1002/chem.202000664)
- [Insertion of [1.1.1]propellane into aromatic disulfides](https://doi.org/10.3762/bjoc.15.114)

:::danger Notice:
Are you asking yourself right now, "That's it?" Yes, that's it! As mentioned above, field specific repositories carry out much of the heavy lifting when it comes to FAIRification, while the digital smart lab environment collects structured data directly along the scientific workflow.
:::

<!--- ![BestPractice](/img/topics/BestPractice.png) <br/>
**Figure 1:** Section of the experimental part in journal publication DOI: [10.1039/d1dt00832c](https://doi.org/10.1039/D1DT00832C), citation of data publication marked in orange. Ti: Shall we highlight supplementary PDFs and IUPAC recommendations from 1970?--->

## Best practices for generic repositories

While field-specific repositories provide significant support for the [FAIRification](/docs/fair) of data along the entire [data life cycle](/docs/data_life_cycle), the preparation of datasets for data publication in generic repositories occurs at the disclosure and publication stage, as long as no (institutional) RDM workflows streamline data publication. Ususally, data is gathered contemporaneous with the preparation of a corresponding manuscript, hence, datasets which are planned to be published with a generic repository require manual [FAIRification](/docs/fair) prior upload and publishing.

To start, all data to be published is collected and ordered in a logical folder structure, e.g. a folder for NMR and another folder for MS data (figure 1). Nested folder structures should be avoided and aspects of [data organisation](/docs/data_organisation), such as file naming, should be taken into account. Researchers should aim for a data package which is as self-explanatory as the supplemental PDFs, they have previously published along scientific articles.

<img align="center" src={useBaseUrl('/img/data_pub/best_practice_generic_folders_content.png')} alt="" width="100%" />

**Figure 1:** Example folder structure and content of the [Lead-by-Example](/docs/lbe_intro) dataset of [Linderazuelene](/docs/datasets/?doi=10.1002/ciuz.201900868).

For further aspects to consider, we provide a non-exhaustive list of generic best practices on what a chemistry dataset should contain and how the chemical data should be represented and described. Please note, that also [domain-specific](/docs/domain_guide) aspects need to be considered for data publication.

- **Data should be published in open formats along the original raw data in proprietary formats.**<br/>[Open formats](/docs/format_standards) for analytical data should be the main choice. However, many analytical instruments provide data in proprietary formats. Not all data in these formats is necessarily also included in the selected open format it was converted to, depending on the specification of the format applied. Hence, the original raw data (in proprietary formats) should also be published, although this data may have limited interoperability. Publishing original raw data is a measure of scientific integrity and allows for unbiased reprocessing and reuse of data. If no open format exists, export as text file, i.e. without any format specification, should be considered.
- **Data should be linked to chemical structures and reactions.**<br/>As analytical data are usually named following lab journal entries, the dataset must include a description of which data correspond to which sample, molecule, or experiment. This should be included in the format used for analytical data. Another solution on that is to provide a [supplementary table](/docs/machine-readable_chemical_structures/#provide-machine-readable-data-as-supplementary-table) (figure 1) within the data package, which should include InChI structure identifiers and SMILES structure codes and additional information such as RInChI reaction identifiers. Second-tier, chemical structures might also be added and represented as [CT files](/docs//ct_files) such as mol or SDfiles (figure 1). [RXNfiles](/docs//ct_files) may be used to describe chemical reactions in a machine readable way.
- **Datasets should include scripts and workflows and information on software used.**<br/>Workflows, i.e. scripts used for data processing and input parameters, also for semi-automatic scripts, should be included. The metadata of the whole dataset should describe the language and version of scripts used as well as other software applied. Best practice is not only to include the code but to add notebooks such as R Notebooks or Jupyther notebooks.
- **Data should be described with metadata and minimum information standards should be followed.**<br/>[Domain-independent](/docs/metadata/#domain-independent-metadata) metadata, via the repositories metadata editor, should be provided. Additionally, [domain-specific](/docs/metadata/#domain-specific-metadata) metadata should be published via the metadata editor, if supported by the repository of choice, within the analytical data or an additional README file. [Minimum information requirements](/docs/metadata/#minimum-information-standards-mi) as set by the chemistry community and followed in manuscripts and previously also in supplementary PDFs should be included.   
- **The provenance information of data should be included.**<br/>Part of that [provenance information](/docs/provenance) is part of the dataset's metadata and should be added via the metadata editor of the repository. All information which previously would have typically been included in the supplemental PDF section on general information and reaction protocolls, e.g. information on methods and instruments used, are provenance information and should be added to a README file, as long as no domain-specific metadata schema is available. This README could be a text file, or written in Markdown, while also providing a human-readable rendered representation as HTML.

:::danger Notice:
Does that sound like a lot of manual work? Avoid extra work by using a [smart lab](/docs/smartlab) digital environments for collecting, processing, analysing and publishing research data, such as [Chemotion](/docs/chemotion_eln)! Plus, you may omit the preparation of supplementary PDFs and use the saved work time to prepare your dataset for publication!
:::

### Best practice examples for generic repositories

- in RADAR4Chem: [Linderazulen aus einer invasiven Pflanze - Delphi und sein violettes Wunder](/docs/datasets/?doi=10.1002/ciuz.201900868)
- in Zenodo: [A data et of 255,000 randomly selected and manually classified extracted ion chromatograms for evaluation of peak detection methods](/docs/datasets/?doi=10.3390/metabo10040162)
- in RADAR: [Synthesis and biological evaluation of highly potent fungicidal deoxy-hygrophorones](/docs/datasets/?doi=10.3390/metabo10040162)
- in DaRus: [Predictive design of ordered mesoporous silica with well-defined, ultra-large mesopores](/docs/tba)

----
Main authors: [ORCID:0000-0003-4480-8661](https://orcid.org/0000-0003-4480-8661), [ORCID:0000-0002-6243-2840](https://orcid.org/0000-0002-6243-2840) and [ORCID:0000-0003-2060-842X](https://orcid.org/0000-0003-2060-842X)
